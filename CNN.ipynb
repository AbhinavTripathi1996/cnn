{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import prettytensor as pt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time \n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#import dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make an array containing the true output class\n",
    "data.test.cls=np.array([i.argmax() for i in data.test.labels])\n",
    "data.validation.cls = np.argmax(data.validation.labels, axis=1)\n",
    "data.test.cls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing variables\n",
    "img_size=28\n",
    "img_size_flat=28*28\n",
    "img_shape=(28,28)\n",
    "num_classes=10\n",
    "num_channels=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input variables\n",
    "x=tf.placeholder(tf.float32,shape=[None,img_size_flat],name='x')\n",
    "x_image=tf.reshape(x,shape=[-1,img_size,img_size,num_channels])\n",
    "y_true=tf.placeholder(tf.float32,shape=[None,num_classes])\n",
    "y_true_cls=tf.arg_max(y_true,dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create the CNN model using prettytensor\n",
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.conv2d(kernel=5, depth=16, name='layer_conv1').max_pool(kernel=2, stride=1).\\\n",
    "        conv2d(kernel=5, depth=36, name='layer_conv2').max_pool(kernel=2, stride=1).flatten().\\\n",
    "        fully_connected(size=128, name='layer_fc1').softmax_classifier(num_classes=num_classes, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining prediction class and type of optimizer used\n",
    "y_pred_cls=tf.arg_max(y_pred,dimension=1)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saving our best fit model in checkpoint directory\n",
    "batch_size=64\n",
    "total_iterations=0\n",
    "best_validation_accuracy = 0.0\n",
    "last_improvement = 0\n",
    "require_improvement = 1000\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'best_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating accuracy of prediction in the validation class\n",
    "batch_size = 256\n",
    "def predict_cls(images, labels, cls_true):\n",
    "    num_images = len(images)\n",
    "    cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "    i = 0\n",
    "    while i < num_images:\n",
    "        j = min(i + batch_size, num_images)\n",
    "        feed_dict = {x: images[i:j, :],y_true: labels[i:j, :]}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        i = j\n",
    "    correct = (cls_true == cls_pred)\n",
    "    return correct, cls_pred\n",
    "def cls_accuracy(correct):\n",
    "    correct_sum = correct.sum()\n",
    "    acc = float(correct_sum) / len(correct)\n",
    "    return acc, correct_sum\n",
    "def validation_accuracy():\n",
    "    correct, _ = predict_cls(images = data.validation.images,labels = data.validation.labels,cls_true = data.validation.cls)\n",
    "    return cls_accuracy(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to train our CNN\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    global best_validation_accuracy\n",
    "    global last_improvement\n",
    "    start_time=time.time()\n",
    "    for i in range (total_iterations,total_iterations+num_iterations):\n",
    "        total_iterations+=1\n",
    "        x_batch,y_true_batch=data.train.next_batch(batch_size)\n",
    "        feed_dict_train={x:x_batch,y_true:y_true_batch}\n",
    "        session.run(optimizer,feed_dict=feed_dict_train)\n",
    "        if total_iterations%100==0 or i==num_iterations-1:\n",
    "            acc_train=session.run(accuracy,feed_dict=feed_dict_train)\n",
    "            acc_validation,_=validation_accuracy()\n",
    "            if acc_validation>best_validation_accuracy:\n",
    "                best_validation_accuracy=acc_validation\n",
    "                last_improvement=total_iterations\n",
    "                saver.save(sess=session,save_path=save_path)\n",
    "                improved_str='*'\n",
    "            else:\n",
    "                improved_str=''\n",
    "            msg = \"Iter: {0:>6}, Train-Batch Accuracy: {1:>6.1%}, Validation Acc: {2:>6.1%} {3}\"\n",
    "            print(msg.format(i + 1, acc_train, acc_validation, improved_str))\n",
    "        if total_iterations-last_improvement>require_improvement:\n",
    "            print(\"model cannot improove any futhher\")\n",
    "            break\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch_size = 256\n",
    "def print_test_accuracy(show_confusion_matrix=False):\n",
    "    num_test = len(data.test.images)\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "    i = 0\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        images = data.test.images[i:j, :]\n",
    "        labels = data.test.labels[i:j, :]\n",
    "        feed_dict = {x: images,y_true: labels}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        i = j\n",
    "    cls_true = data.test.cls\n",
    "    correct = (cls_true == cls_pred)\n",
    "    correct_sum = correct.sum()\n",
    "    acc = float(correct_sum) / num_test\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session=tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 10.2% (1023 / 10000)\n"
     ]
    }
   ],
   "source": [
    "#accuracy before training\n",
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    100, Train-Batch Accuracy:  94.5%, Validation Acc:  94.7% *\n",
      "Iter:    200, Train-Batch Accuracy:  96.1%, Validation Acc:  96.7% *\n",
      "Iter:    300, Train-Batch Accuracy:  98.4%, Validation Acc:  97.4% *\n",
      "Iter:    400, Train-Batch Accuracy:  99.2%, Validation Acc:  97.8% *\n",
      "Iter:    500, Train-Batch Accuracy:  98.4%, Validation Acc:  98.3% *\n",
      "Iter:    600, Train-Batch Accuracy:  98.0%, Validation Acc:  98.4% *\n",
      "Iter:    700, Train-Batch Accuracy:  99.6%, Validation Acc:  98.5% *\n",
      "Iter:    800, Train-Batch Accuracy:  98.4%, Validation Acc:  98.3% \n",
      "Iter:    900, Train-Batch Accuracy: 100.0%, Validation Acc:  98.8% *\n",
      "Iter:   1000, Train-Batch Accuracy:  99.6%, Validation Acc:  98.5% \n",
      "Iter:   1100, Train-Batch Accuracy:  99.2%, Validation Acc:  98.8% \n",
      "Iter:   1200, Train-Batch Accuracy:  98.8%, Validation Acc:  98.8% *\n",
      "Iter:   1300, Train-Batch Accuracy:  99.2%, Validation Acc:  98.7% \n",
      "Iter:   1400, Train-Batch Accuracy: 100.0%, Validation Acc:  98.8% *\n",
      "Iter:   1500, Train-Batch Accuracy:  98.8%, Validation Acc:  98.9% *\n",
      "Iter:   1600, Train-Batch Accuracy:  98.8%, Validation Acc:  98.8% \n",
      "Iter:   1700, Train-Batch Accuracy:  98.4%, Validation Acc:  99.0% *\n",
      "Iter:   1800, Train-Batch Accuracy: 100.0%, Validation Acc:  98.9% \n",
      "Iter:   1900, Train-Batch Accuracy:  98.4%, Validation Acc:  98.8% \n",
      "Iter:   2000, Train-Batch Accuracy: 100.0%, Validation Acc:  98.8% \n",
      "Iter:   2100, Train-Batch Accuracy:  98.4%, Validation Acc:  98.8% \n",
      "Iter:   2200, Train-Batch Accuracy: 100.0%, Validation Acc:  98.7% \n",
      "Iter:   2300, Train-Batch Accuracy:  99.6%, Validation Acc:  99.0% \n",
      "Iter:   2400, Train-Batch Accuracy:  99.6%, Validation Acc:  99.0% \n",
      "Iter:   2500, Train-Batch Accuracy:  99.6%, Validation Acc:  98.9% \n",
      "Iter:   2600, Train-Batch Accuracy: 100.0%, Validation Acc:  98.9% \n",
      "Iter:   2700, Train-Batch Accuracy: 100.0%, Validation Acc:  98.9% \n",
      "model cannot improove any futhher\n",
      "Time usage: 1:00:45\n"
     ]
    }
   ],
   "source": [
    "#train our CNN\n",
    "optimize(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/best_validation\n"
     ]
    }
   ],
   "source": [
    "#using our best fit model saved in checkpoint directory\n",
    "saver.restore(sess=session, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 98.8% (9883 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
